{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Start - pip install ucimlrepo / import / from [REQUIRED]"
      ],
      "metadata": {
        "id": "zMo66OfXgwHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo # This is not included in Colab so you have to install it first"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaQXC1YxC-JW",
        "outputId": "4b25f5e9-caef-4f3d-c207-7d6bd0b27c1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1yvcrpgD6yOt"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import asyncio\n",
        "import cProfile\n",
        "import logging\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os, sys\n",
        "import pstats\n",
        "import pandas as pd\n",
        "import socket\n",
        "import struct\n",
        "import torch\n",
        "import tornado\n",
        "import traceback\n",
        "#\n",
        "from collections import Counter\n",
        "from datetime import datetime\n",
        "from typing import List\n",
        "from math import sqrt\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "#\n",
        "logging.basicConfig(level = logging.INFO, format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "#\n",
        "dir2 = os.path.abspath('')\n",
        "dir1 = os.path.dirname(dir2)\n",
        "if not dir1 in sys.path:\n",
        "    sys.path.append(dir1)\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Data Processing [REQUIRED]"
      ],
      "metadata": {
        "id": "XyXdo-YLgpRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Fetching the dataset using ucimlrepo package"
      ],
      "metadata": {
        "id": "mN7VABM-77sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17)"
      ],
      "metadata": {
        "id": "KJvLjCLr8P1Y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Data Processing to X and y"
      ],
      "metadata": {
        "id": "K1AC0uVn8kF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Putting dataset into X (features) and Y (target), X = what we are evaluating, y = the diagnosis\n",
        "#\n",
        "X = breast_cancer_wisconsin_diagnostic.data.features\n",
        "y = breast_cancer_wisconsin_diagnostic.data.targets\n",
        "#\n",
        "# This will be used in FAM to define the number of features\n",
        "Xfeaturenum = len(X.columns)\n",
        "Xfeaturenum = int(Xfeaturenum)\n",
        "#"
      ],
      "metadata": {
        "id": "MondztfU8s6i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the columns\n",
        "print(X.columns)"
      ],
      "metadata": {
        "id": "VrJ_b01KKcE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da9dde9-d525-4368-c140-e9a5341881fa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1',\n",
            "       'compactness1', 'concavity1', 'concave_points1', 'symmetry1',\n",
            "       'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2',\n",
            "       'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
            "       'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3',\n",
            "       'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
            "       'symmetry3', 'fractal_dimension3'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show X values\n",
        "print(X)"
      ],
      "metadata": {
        "id": "ZqqDRg2gHqhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493bfdb1-fda0-40ec-fe65-b6b42a40cdf5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     radius1  texture1  perimeter1   area1  smoothness1  compactness1  \\\n",
            "0      17.99     10.38      122.80  1001.0      0.11840       0.27760   \n",
            "1      20.57     17.77      132.90  1326.0      0.08474       0.07864   \n",
            "2      19.69     21.25      130.00  1203.0      0.10960       0.15990   \n",
            "3      11.42     20.38       77.58   386.1      0.14250       0.28390   \n",
            "4      20.29     14.34      135.10  1297.0      0.10030       0.13280   \n",
            "..       ...       ...         ...     ...          ...           ...   \n",
            "564    21.56     22.39      142.00  1479.0      0.11100       0.11590   \n",
            "565    20.13     28.25      131.20  1261.0      0.09780       0.10340   \n",
            "566    16.60     28.08      108.30   858.1      0.08455       0.10230   \n",
            "567    20.60     29.33      140.10  1265.0      0.11780       0.27700   \n",
            "568     7.76     24.54       47.92   181.0      0.05263       0.04362   \n",
            "\n",
            "     concavity1  concave_points1  symmetry1  fractal_dimension1  ...  radius3  \\\n",
            "0       0.30010          0.14710     0.2419             0.07871  ...   25.380   \n",
            "1       0.08690          0.07017     0.1812             0.05667  ...   24.990   \n",
            "2       0.19740          0.12790     0.2069             0.05999  ...   23.570   \n",
            "3       0.24140          0.10520     0.2597             0.09744  ...   14.910   \n",
            "4       0.19800          0.10430     0.1809             0.05883  ...   22.540   \n",
            "..          ...              ...        ...                 ...  ...      ...   \n",
            "564     0.24390          0.13890     0.1726             0.05623  ...   25.450   \n",
            "565     0.14400          0.09791     0.1752             0.05533  ...   23.690   \n",
            "566     0.09251          0.05302     0.1590             0.05648  ...   18.980   \n",
            "567     0.35140          0.15200     0.2397             0.07016  ...   25.740   \n",
            "568     0.00000          0.00000     0.1587             0.05884  ...    9.456   \n",
            "\n",
            "     texture3  perimeter3   area3  smoothness3  compactness3  concavity3  \\\n",
            "0       17.33      184.60  2019.0      0.16220       0.66560      0.7119   \n",
            "1       23.41      158.80  1956.0      0.12380       0.18660      0.2416   \n",
            "2       25.53      152.50  1709.0      0.14440       0.42450      0.4504   \n",
            "3       26.50       98.87   567.7      0.20980       0.86630      0.6869   \n",
            "4       16.67      152.20  1575.0      0.13740       0.20500      0.4000   \n",
            "..        ...         ...     ...          ...           ...         ...   \n",
            "564     26.40      166.10  2027.0      0.14100       0.21130      0.4107   \n",
            "565     38.25      155.00  1731.0      0.11660       0.19220      0.3215   \n",
            "566     34.12      126.70  1124.0      0.11390       0.30940      0.3403   \n",
            "567     39.42      184.60  1821.0      0.16500       0.86810      0.9387   \n",
            "568     30.37       59.16   268.6      0.08996       0.06444      0.0000   \n",
            "\n",
            "     concave_points3  symmetry3  fractal_dimension3  \n",
            "0             0.2654     0.4601             0.11890  \n",
            "1             0.1860     0.2750             0.08902  \n",
            "2             0.2430     0.3613             0.08758  \n",
            "3             0.2575     0.6638             0.17300  \n",
            "4             0.1625     0.2364             0.07678  \n",
            "..               ...        ...                 ...  \n",
            "564           0.2216     0.2060             0.07115  \n",
            "565           0.1628     0.2572             0.06637  \n",
            "566           0.1418     0.2218             0.07820  \n",
            "567           0.2650     0.4087             0.12400  \n",
            "568           0.0000     0.2871             0.07039  \n",
            "\n",
            "[569 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show y values\n",
        "print(y)"
      ],
      "metadata": {
        "id": "0d2HLyhJILz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be250137-2ac9-4dbf-a1d4-7402463b1d3a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Diagnosis\n",
            "0           M\n",
            "1           M\n",
            "2           M\n",
            "3           M\n",
            "4           M\n",
            "..        ...\n",
            "564         M\n",
            "565         M\n",
            "566         M\n",
            "567         M\n",
            "568         B\n",
            "\n",
            "[569 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3 Data Standardization (sklearn)"
      ],
      "metadata": {
        "id": "22elU0vuKoLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode non numeric values to 1/0\n",
        "label_encoder = LabelEncoder()\n",
        "scalar = MinMaxScaler(feature_range=(0, 1))\n",
        "X = scalar.fit_transform(X)\n",
        "# Encode y to a 1d array using .ravel()\n",
        "y_encoded = label_encoder.fit_transform(y.values.ravel())\n",
        "# Now split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "mbPbTJ7sOXLQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now show standardized X\n",
        "print(X_train)"
      ],
      "metadata": {
        "id": "hD_dv0qI8z7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828bb41a-858d-488e-db0c-5cf316dbab36"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.1452506  0.26445722 0.14249188 ... 0.22333333 0.26197516 0.14167651]\n",
            " [0.18074684 0.41494758 0.17275931 ... 0.25721649 0.27597083 0.14154532]\n",
            " [0.43348005 0.174163   0.41814664 ... 0.38797251 0.23910901 0.09891119]\n",
            " ...\n",
            " [0.11619102 0.29117349 0.11077327 ... 0.17360825 0.17524147 0.17263545]\n",
            " [0.12963226 0.28779168 0.11706171 ... 0.         0.06780997 0.06919848]\n",
            " [0.21434995 0.4808928  0.21235575 ... 0.33171821 0.10782574 0.21172767]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now show standardized y\n",
        "print (y_test)"
      ],
      "metadata": {
        "id": "MdyjG0hQ83QP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714182ed-56cc-4e8c-c86d-e4054b73b1c0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 0 1 0 1 0 1 0 1 0\n",
            " 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 1\n",
            " 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
            " 1 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 ML with KNN SKLEARN [Optional]"
      ],
      "metadata": {
        "id": "cNQrU4scfEne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Training and Predicting with the KNN model (sklearn)"
      ],
      "metadata": {
        "id": "qxSPkkwVbyEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_predk = classifier.predict(X_test)"
      ],
      "metadata": {
        "id": "kr1CthFKb0un"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show the y.pred (predicted value) vs the y (actual value)\n",
        "print(np.concatenate((y_predk.reshape(len(y_predk),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "NDRZXQgVb-Ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d88aab3-7c2a-4226-b32f-2fe826fd3825"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Calculate and Print Metrics (KNN sklearn)"
      ],
      "metadata": {
        "id": "xd1bg7xmjI2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate KNN Metrics\n",
        "accuracyk = accuracy_score(y_test, y_predk)\n",
        "auc_rock = roc_auc_score(y_test, y_predk)\n",
        "f1k = f1_score(y_test, y_predk)\n",
        "precisionk = precision_score(y_test, y_predk)\n",
        "sensitivityk = recall_score(y_test, y_predk)\n",
        "tnk, fpk, fnk, tpk = confusion_matrix(y_test, y_predk).ravel()\n",
        "specificityk = tnk / (tnk + fpk)"
      ],
      "metadata": {
        "id": "mzT1743njJ5A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print KNN Metrics\n",
        "print('### KNN Metrics ###')\n",
        "print(f\"Accuracy: {accuracyk}\")\n",
        "print(f\"AUC-ROC: {auc_rock}\")\n",
        "print(f\"F1 Score: {f1k}\")\n",
        "print(f\"Precision: {precisionk}\")\n",
        "print(f\"Sensitivity (Recall): {sensitivityk}\")\n",
        "print(f\"Specificity: {specificityk}\")\n",
        "print(f\"True Negatives: {tnk}\")\n",
        "print(f\"False Positives: {fpk}\")\n",
        "print(f\"False Negatives: {fnk}\")\n",
        "print(f\"True Positives: {tpk}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWJjE7tBjTmC",
        "outputId": "96f98c14-a886-44b1-f853-bd2b731d8432"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### KNN Metrics ###\n",
            "Accuracy: 0.9649122807017544\n",
            "AUC-ROC: 0.9574468085106382\n",
            "F1 Score: 0.9555555555555556\n",
            "Precision: 1.0\n",
            "Sensitivity (Recall): 0.9148936170212766\n",
            "Specificity: 1.0\n",
            "True Negatives: 67\n",
            "False Positives: 0\n",
            "False Negatives: 4\n",
            "True Positives: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 ML with Fuzzy ARTMAP (FAM) [Optional]"
      ],
      "metadata": {
        "id": "mQVtLRw4fa9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 FAM Tensor Data Prep"
      ],
      "metadata": {
        "id": "8esjXoVB7B5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)  # Convert training input data to PyTorch tensor with float32 data type\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)  # Convert training target data to PyTorch tensor with float32 data type\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)    # Convert testing input data to PyTorch tensor with float32 data type\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)    # Convert testing target data to PyTorch tensor with float32 data type"
      ],
      "metadata": {
        "id": "BlCFfYDP7LQW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize FuzzyARTMAP\n",
        "num_features = Xfeaturenum * 2 # Number of features in your data\n",
        "num_categories = 2  # Number of unique categories in your data\n",
        "# choice_param = 0.5  # Not really a hyperparameter, and should be much smaller see Carpenter et al., 1992\n",
        "learning_rate = 0.1  # Hyperparameter, you may need to tune this\n",
        "vigilance = 0.9  # Hyperparameter, you may need to tune this"
      ],
      "metadata": {
        "id": "OH76rpS27MIl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 FAM Class and Methods"
      ],
      "metadata": {
        "id": "tRmTFmrOZgR7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fuzzy ARTMAP Class (Below)\n",
        "\n",
        "**Description:**\n",
        "The `FuzzyArtMap` class is an implementation of a Fuzzy ARTMAP neural network. This class is designed to perform pattern recognition and classification tasks. Fuzzy ARTMAP is particularly useful for tasks where the number of categories or classes can change dynamically. It can adapt to new categories without forgetting the previously learned ones.\n",
        "\n",
        "**How It Works:**\n",
        "- **Initialization Parameters:** The class takes various parameters during initialization, including the size of input and F2 layers, the number of categories, and vigilance criteria.\n",
        "- **Resonance Search:** It uses the `_resonance_search_vector` method to find the most resonant F2 node for a given input pattern based on vigilance criteria.\n",
        "- **Training:** The `train` method updates weights based on input patterns and their corresponding class vectors.\n",
        "- **Prediction:** The `predict` method makes predictions for input patterns by finding the most resonant F2 node.\n",
        "- **Complement Encoding:** It provides a static method, `complement_encode`, to perform complement encoding of input vectors.\n",
        "- **Handling New Nodes:** The class handles the addition of new F2 nodes when needed.\n",
        "\n",
        "**Why It's Needed:**\n",
        "- Fuzzy ARTMAP is a versatile neural network that can adapt to new categories, making it suitable for tasks with changing or growing class sets.\n",
        "- It provides a mechanism for incremental learning, allowing the network to remember and adapt to previously learned patterns.\n",
        "- Fuzzy ARTMAP is used in various applications, including pattern recognition, classification, and adaptive learning.\n",
        "\n",
        "**Components:**\n",
        "- Input Layer (F1): Represents input patterns.\n",
        "- F2 Layer: Contains category nodes for pattern recognition.\n",
        "- Complement Coding: Utilizes complement encoding to enhance pattern representation.\n",
        "- Vigilance Parameters: Control the matching criteria for resonance.\n",
        "- Weight Matrices: Store connection weights between layers.\n",
        "- Training and Prediction Methods: Implement the learning and prediction processes.\n",
        "\n"
      ],
      "metadata": {
        "id": "kTndQa0KAxa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FuzzyArtMap:\n",
        "    def __init__(self,\n",
        "                 f1_size: int = 10,\n",
        "                 f2_size: int = 10,\n",
        "                 number_of_labels: int = 2,\n",
        "                 rho_a_bar = 0,\n",
        "                 max_nodes = None,\n",
        "                 committed_beta = 0.75, ):\n",
        "        \"\"\"\n",
        "        Initialize Fuzzy ARTMAP instance and parameters\n",
        "        Keyword arguments:\n",
        "        f1_size - the number of elements in the compliment encoded vector (two-times the size of the input vector)\n",
        "        f2_size - the initial number of coding category nodes - this will automatically grow up to max_nodes, unlimited if None\n",
        "        number_of_labels - the compliment encoded number of labels for multi-label classification (e.g. for relevant, privilege this would be set to 4, for just relevant - 2)\n",
        "        rho_a_bar - the baseline vigilence parameter to set the degree of match required to trigger resonance\n",
        "        max_nodes - the maximum number of f2 nodes to grow to (Implementing the Max-Nodes mode of Carpenter, Grossberg, & Reynolds, 1995 - \"A Fuzzy ARTMAP Nonparametric Probability Estimator for Nonstationary Pattern Recognition Problems\")\n",
        "        committed_beta - the learning rate for nodes that have already been commited (see Fast-Commit Slow-Recode Option in Carpenter et al., 1992)\n",
        "        \"\"\"\n",
        "        if rho_a_bar < 0.0 or rho_a_bar > 1.0:\n",
        "            raise ValueError(f\"rho_a_bar must be between 0.0 and 1.0, received {rho_a_bar}\")\n",
        "\n",
        "        if committed_beta < 0.0 or committed_beta > 1.0:\n",
        "            raise ValueError(f\"committed_beta must be between 0.0 and 1.0, received {committed_beta}\")\n",
        "\n",
        "        self.alpha = 0.001  # \"Choice\" parameter > 0. Set small for the conservative limit (Fuzzy AM paper, Sect.3)\n",
        "        self.dtype = torch.float\n",
        "        self.beta = 1  # Learning rate. Set to 1 for fast learning\n",
        "        self.beta_ab = 1 #ab learning rate - Enables Slow-lEarning mode from Carpenter, Grossberg, & Reynolds\n",
        "\n",
        "        self.rho_ab = 0.95          # Map field vigilance, in [0,1]\n",
        "        self.epsilon = 0.001        # Fab mismatch raises ARTa vigilance to this much above what is needed to reset ARTa\n",
        "        self.device = torch.device(\"cpu\")\n",
        "\n",
        "        self.rho_a_bar = rho_a_bar  # Baseline vigilance for ARTa, in range [0,1]\n",
        "        self.committed_beta = committed_beta\n",
        "        self.max_nodes = max_nodes\n",
        "        self.weight_a = torch.ones((f2_size, f1_size), device=self.device, dtype=self.dtype)\n",
        "        self.input_vector_sum = f1_size / 2\n",
        "        self.weight_ab = torch.ones((f2_size, number_of_labels), device=self.device, dtype=self.dtype)\n",
        "        self.A_and_w = torch.empty(self.weight_a.shape, device=self.device, dtype=self.dtype)\n",
        "        logger.info(f\"f1_size: {f1_size}, f2_size:{f2_size}, committed beta = {self.committed_beta}\")\n",
        "\n",
        "        self.committed_nodes = set()\n",
        "        self.updated_nodes = set()\n",
        "        self.node_increase_step = 50 # number of F2 nodes to add when required\n",
        "        self.number_of_increases = 0\n",
        "\n",
        "    def _resonance_search_vector(self, input_vector: torch.tensor, already_reset_nodes: List[int], rho_a: float):\n",
        "        \"\"\"\n",
        "        Search for a resonating F2 node based on input vector and vigilance criteria.\n",
        "\n",
        "        Parameters:\n",
        "        - input_vector: The input vector for which resonance is being searched.\n",
        "        - already_reset_nodes: List of nodes that have already been reset.\n",
        "        - rho_a: The vigilance parameter for ARTa.\n",
        "        \"\"\"\n",
        "        resonant_a = False\n",
        "        N, S, T = self.calculate_activation(input_vector)\n",
        "        _, indices = torch.sort(T, stable=True, descending=True)\n",
        "        all_membership_degrees = S / self.input_vector_sum\n",
        "        T[already_reset_nodes] = torch.zeros((len(already_reset_nodes), ), dtype=self.dtype, device=self.device)\n",
        "        while not resonant_a:\n",
        "            for J in indices:\n",
        "                if J.item() in already_reset_nodes:\n",
        "                    continue\n",
        "\n",
        "                if all_membership_degrees[J].item() >= rho_a or math.isclose(all_membership_degrees[J].item(), rho_a):\n",
        "                    resonant_a = True\n",
        "                    break\n",
        "                else:\n",
        "                    resonant_a = False\n",
        "                    already_reset_nodes.append(indices[J].item())\n",
        "                    T[indices[J].item()] = 0\n",
        "\n",
        "            # Creating a new node if we've reset all of them\n",
        "            if len(already_reset_nodes) >= N:\n",
        "                if self.max_nodes is None or self.max_nodes >= (N + self.node_increase_step):\n",
        "                    self.weight_a = torch.vstack((self.weight_a, torch.ones((self.node_increase_step,  self.weight_a.shape[1]), device=self.device, dtype=self.dtype)))\n",
        "                    self.weight_ab = torch.vstack((self.weight_ab, torch.ones((self.node_increase_step, self.weight_ab.shape[1]), device=self.device, dtype=self.dtype)))\n",
        "                    self.A_and_w = torch.vstack((self.A_and_w, torch.empty((self.node_increase_step,  self.weight_a.shape[1]), device=self.device, dtype=self.dtype)))\n",
        "                    self.number_of_increases += 1\n",
        "                else:\n",
        "                    self.rho_ab = 0\n",
        "                    self.beta_ab = 0.75\n",
        "                    self.rho_a_bar = 0\n",
        "                    rho_a = self.rho_a_bar\n",
        "                    logger.info(f\"Maximum number of nodes reached, {len(already_reset_nodes)} - adjusting rho_ab to {self.rho_ab} and beta_ab to {self.beta_ab}\")\n",
        "                    already_reset_nodes.clear()\n",
        "                N, S, T = self.calculate_activation(input_vector)\n",
        "                _, indices = torch.sort(T, stable=True, descending=True)\n",
        "                all_membership_degrees = S / self.input_vector_sum\n",
        "                T[already_reset_nodes] = torch.zeros((len(already_reset_nodes), ), dtype=self.dtype, device=self.device)\n",
        "\n",
        "        return J.item(), all_membership_degrees[J].item()\n",
        "\n",
        "    def calculate_activation(self, input_vector):\n",
        "        \"\"\"\n",
        "        Calculate the activation levels for F2 nodes based on the input vector.\n",
        "\n",
        "        Parameters:\n",
        "        - input_vector: The input vector for which activation is calculated.\n",
        "        \"\"\"\n",
        "        N = self.weight_a.shape[0]  # Count how many F2a nodes we have\n",
        "\n",
        "        torch.minimum(input_vector.repeat(N,1), self.weight_a, out=self.A_and_w) # Fuzzy AND = min\n",
        "        S = torch.sum(self.A_and_w, 1) # Row vector of signals to F2 nodes\n",
        "        T = S / (self.alpha + torch.sum(self.weight_a, 1)) # Choice function vector for F2\n",
        "        return N,S,T\n",
        "\n",
        "    def train(self, input_vector: torch.tensor, class_vector: torch.tensor):\n",
        "        \"\"\"\n",
        "        Train the FAM network with an input vector and class vector.\n",
        "\n",
        "        Parameters:\n",
        "        - input_vector: The input vector used for training.\n",
        "        - class_vector: The class vector used for training.\n",
        "        \"\"\"\n",
        "        rho_a = self.rho_a_bar # We start off with ARTa vigilance at baseline\n",
        "        resonant_ab = False # Not resonating in the Fab match layer\n",
        "        already_reset_nodes = [] # We haven't rest any ARTa nodes for this input pattern yet, maintain list between resonance searches of Fa\n",
        "\n",
        "        class_vector = class_vector.to(self.device)\n",
        "        input_vector = input_vector.to(self.device)\n",
        "        class_vector_sum = torch.sum(class_vector, 1)\n",
        "        while not resonant_ab:\n",
        "            J, x = self._resonance_search_vector(input_vector, already_reset_nodes, rho_a)\n",
        "\n",
        "            z = torch.minimum(class_vector, self.weight_ab[J, None])\n",
        "\n",
        "            resonance = torch.sum(z, 1)/class_vector_sum\n",
        "            if resonance > self.rho_ab or math.isclose(resonance, self.rho_ab):\n",
        "                resonant_ab = True\n",
        "            else:\n",
        "                already_reset_nodes.append(J)\n",
        "                rho_a = x + self.epsilon\n",
        "                if rho_a > 1.0:\n",
        "                    rho_a = 1.0 - self.epsilon\n",
        "\n",
        "        self.updated_nodes.add(J)\n",
        "        if J in self.committed_nodes:\n",
        "            beta = self.committed_beta\n",
        "        else:\n",
        "            beta = self.beta\n",
        "\n",
        "        self.weight_a[J, None] = (beta * torch.minimum(input_vector, self.weight_a[J, None])) + ((1-beta) * self.weight_a[J, None])\n",
        "        self.weight_ab[J, None] = (self.beta_ab * z) + ((1-self.beta_ab) * self.weight_ab[J, None])\n",
        "        self.committed_nodes.add(J)\n",
        "\n",
        "    def fit(self, input_vectors, class_vectors):\n",
        "        \"\"\"\n",
        "        Train the FAM network on a batch of input vectors and class vectors.\n",
        "\n",
        "        Parameters:\n",
        "        - input_vectors: A batch of input vectors.\n",
        "        - class_vectors: A batch of class vectors.\n",
        "        \"\"\"\n",
        "        for vector_index, input_vector in enumerate(input_vectors):\n",
        "            self.train(input_vector, class_vectors[vector_index])\n",
        "        self.updated_nodes.clear()\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def complement_encode(original_vector: torch.tensor) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Complement encode the original input vector.\n",
        "\n",
        "        Parameters:\n",
        "        - original_vector: The original input vector to be complement-encoded.\n",
        "        \"\"\"\n",
        "        complement = 1-original_vector\n",
        "        complement_encoded_value = torch.hstack((original_vector,complement))\n",
        "        return complement_encoded_value\n",
        "\n",
        "    def predict(self, input_vector: torch.tensor):\n",
        "        \"\"\"\n",
        "        Predict the class membership and membership degree for an input vector.\n",
        "\n",
        "        Parameters:\n",
        "        - input_vector: The input vector for which prediction is made.\n",
        "        \"\"\"\n",
        "        rho_a = 0 # set ARTa vigilance to first match\n",
        "        J, membership_degree = self._resonance_search_vector(input_vector, [], rho_a)\n",
        "\n",
        "        # (Called x_ab in Fuzzy ARTMAP paper)\n",
        "        return self.weight_ab[J, None], membership_degree # Fab activation vector & fuzzy membership value\n",
        "\n",
        "    def save_model(self, descriptor: str):\n",
        "        \"\"\"\n",
        "        Save the FAM model to a file with a timestamp and descriptor.\n",
        "\n",
        "        Parameters:\n",
        "        - descriptor: A descriptor for the saved model file.\n",
        "        \"\"\"\n",
        "        model_timestamp = datetime.now().isoformat().replace(\"-\", \"_\").replace(\":\", \"_\").replace(\".\", \"_\")\n",
        "        cleaned_descriptor = descriptor.replace(\"-\", \"_\").replace(\":\", \"_\").replace(\".\", \"_\")\n",
        "        model_path = f\"models/famgd_{model_timestamp}_{cleaned_descriptor}.pt\"\n",
        "        torch.save((self.weight_a, self.weight_ab, self.committed_nodes), model_path)\n",
        "        return model_path\n",
        "\n",
        "    def get_number_of_nodes(self):\n",
        "        \"\"\"\n",
        "        Get the number of nodes in the F2 layer.\n",
        "        \"\"\"\n",
        "        return self.weight_ab.shape[0]\n",
        "\n",
        "    def get_number_of_increases(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the number of node increases during training.\n",
        "        \"\"\"\n",
        "        return self.number_of_increases\n",
        "\n",
        "    def get_increase_size(self) -> int:\n",
        "        \"\"\"\n",
        "        Get the size of node increases during training.\n",
        "        \"\"\"\n",
        "        return self.node_increase_step\n",
        "\n",
        "    def get_committed_nodes(self) -> str:\n",
        "        \"\"\"\n",
        "        Get the list of committed nodes.\n",
        "        \"\"\"\n",
        "        return \",\".join([str(n) for n in self.committed_nodes])\n",
        "\n",
        "    def get_weight_a(self) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Get the weight matrix of the F1 to F2 connections.\n",
        "        \"\"\"\n",
        "        return self.weight_a\n",
        "\n",
        "    def get_weight_ab(self) -> torch.tensor:\n",
        "        \"\"\"\n",
        "        Get the weight matrix of the F2 to class connections.\n",
        "        \"\"\"\n",
        "        return self.weight_ab"
      ],
      "metadata": {
        "id": "r7zB5oiGSJuK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Procedural Fuzzy ARTMAP Class (Below)\n",
        "\n",
        "**Description:**\n",
        "The `ProceduralFuzzyArtMap` class is an alternative implementation of a Fuzzy ARTMAP neural network using NumPy for computations. It serves the same purpose as the `FuzzyArtMap` class but uses a different approach.\n",
        "\n",
        "**How It Works:**\n",
        "- **Initialization Parameters:** This class accepts various parameters, such as layer sizes, vigilance criteria, and learning rates.\n",
        "- **Resonance Search:** It uses the `_resonance_search` method to find the most resonant F2 node based on vigilance criteria.\n",
        "- **Training:** The `train` method updates weights based on input patterns and class vectors.\n",
        "- **Prediction:** The `predict` method makes predictions for input patterns.\n",
        "- **Complement Encoding:** Provides a static method, `complement_encode`, for complement encoding.\n",
        "- **Handling New Nodes:** The class appends new rows to weight matrices to add new nodes when required.\n",
        "\n",
        "**Why It's Needed:**\n",
        "- Procedural Fuzzy ARTMAP offers an alternative implementation for pattern recognition and classification tasks.\n",
        "- It uses NumPy for computations, making it suitable for scenarios where PyTorch is not preferred or available.\n",
        "\n",
        "**Components:**\n",
        "- Input Layer (F1): Represents input patterns.\n",
        "- F2 Layer: Contains category nodes for pattern recognition.\n",
        "- Complement Coding: Utilizes complement encoding for enhanced pattern representation.\n",
        "- Vigilance Parameters: Control the matching criteria for resonance.\n",
        "- Weight Matrices: Store connection weights between layers.\n",
        "- Training and Prediction Methods: Implement the learning and prediction processes.\n",
        "- Category Growth Control: Allows or disallows the addition of new nodes based on the `allow_category_growth` parameter."
      ],
      "metadata": {
        "id": "SHPLliS0A2qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProceduralFuzzyArtMap:\n",
        "    def __init__(self, f1_size: int = 10, f2_size: int = 10, number_of_categories: int = 2, rho_a_bar = 0):\n",
        "        self.alpha = 0.001  # \"Choice\" parameter > 0. Set small for the conservative limit (Fuzzy AM paper, Sect.3)\n",
        "        self.beta = 1  # Learning rate. Set to 1 for fast learning\n",
        "        self.rho_a_bar = rho_a_bar  # Baseline vigilance for ARTa, in range [0,1]\n",
        "        # use f1_size instead\n",
        "        #self.M = size(a,1)  # Number of input components. Derived from data\n",
        "                            # NB: Total input size = 2M (due to complement)\n",
        "        # use f2_size instead\n",
        "        # self.N = 20         # Number of available coding nodes\n",
        "                            # We start with some resonably large number\n",
        "                            # then, if we need to, can add more uncommitted\n",
        "        # self.L = size(bmat,1)       # Number of output nodes. Derived from data ??? number output classes ????\n",
        "        self.rho_ab = 0.95          # Map field vigilance, in [0,1]\n",
        "        self.epsilon = 0.001        # Fab mismatch raises ARTa vigilance to this\n",
        "                                    # much above what is needed to reset ARTa\n",
        "        self.weight_a = np.ones((f2_size, f1_size)) # Initial weights in ARTa. All set to 1 Row-i, col-j entry = weight from input node i to F2 coding node j\n",
        "        self.weight_ab = np.ones((f2_size, number_of_categories))  # Row-k, col-j entry = weight from ARTa F2  node j to Map Field node k\n",
        "        self.committed_nodes = []\n",
        "\n",
        "    def _resonance_search(self, input_vector, already_reset_nodes, rho_a, allow_category_growth = True):\n",
        "        resonant_a = False\n",
        "        while not resonant_a:\n",
        "            # In search of a resonating ARTa node...\n",
        "            # Find the winning, matching ARTa node\n",
        "\n",
        "            N = self.weight_a.shape[0]\n",
        "            # Count how many F2a nodes we have\n",
        "\n",
        "            A_for_each_F2_node = input_vector * np.ones((N,1))\n",
        "            # Matrix containing a copy of A for each F2 node. Useful for Matlab\n",
        "\n",
        "            A_AND_w = np.minimum(A_for_each_F2_node, self.weight_a)\n",
        "            # Fuzzy AND = min\n",
        "\n",
        "            S = np.sum(A_AND_w, axis=1) # might be wrong operator\n",
        "            # Row vector of signals to F2 nodes\n",
        "\n",
        "            T = S / (self.alpha + np.sum(self.weight_a, axis=1))\n",
        "            # Choice function vector for F2\n",
        "\n",
        "            # Set all the reset nodes to zero\n",
        "            T[already_reset_nodes] = np.zeros((len(already_reset_nodes), ), dtype=np.float32)\n",
        "\n",
        "            # Finding the winning node, J\n",
        "\n",
        "            J = np.argmax(T)\n",
        "            # Matlab function max works such that J is the lowest index of max T elements, as\n",
        "            # desired. J is the winning F2 category node\n",
        "\n",
        "            # y = np.zeros((N, 1))\n",
        "            # y[J]=1\n",
        "            # Activities of F2. All zero, except J\n",
        "\n",
        "            w_J = self.weight_a[J, :]  # ?????\n",
        "            # Weight vector into winning F2 node, J\n",
        "\n",
        "            x = np.minimum(input_vector, w_J)\n",
        "            # Fuzzy version of 2/3 rule. x is F1 activity\n",
        "            # NB: We could also use J-th element of S\n",
        "            # since the top line of the match fraction\n",
        "            # |I and w|/|I| is sum(x), which is\n",
        "            # S = sum(A_AND_w) from above\n",
        "\n",
        "            #####################################\n",
        "            ######## Testing if the winning node resonates in ARTa\n",
        "\n",
        "            if np.sum(x)/np.sum(input_vector) >= rho_a:\n",
        "                # If a match, we're done\n",
        "                resonant_a = True         # ARTa resonates\n",
        "                # The while resonant_a == 0 command will stop looping\n",
        "                # now, so we exit the while loop and go onto to Fab\n",
        "            else:\n",
        "                # If mismatch then we reset\n",
        "                resonant_a = False     # So, still not resonating\n",
        "                already_reset_nodes.append(J)\n",
        "                # Record that node J has been reset already.\n",
        "\n",
        "            #####################################\n",
        "            # Creating a new node if we've reset all of them\n",
        "\n",
        "            if len(already_reset_nodes) == N:\n",
        "                if allow_category_growth:\n",
        "                    # If all F2a nodes reset\n",
        "                    self.weight_a = np.vstack((self.weight_a, np.ones((1, self.weight_a.shape[1]))))\n",
        "                    self.weight_ab = np.vstack((self.weight_ab, np.ones((1, self.weight_ab.shape[1]))))\n",
        "                else:\n",
        "                    return -1, None\n",
        "            # Give the new F2a node a w_ab entry\n",
        "            # Now go back and this new node should win\n",
        "        return J, x\n",
        "\n",
        "    def train(self, input_vector: np.array, class_vector: np.array):\n",
        "        rho_a = self.rho_a_bar\n",
        "        # We start off with ARTa vigilance at baseline\n",
        "\n",
        "        resonant_ab = False\n",
        "        # Not resonating in the Fab match layer either\n",
        "\n",
        "        already_reset_nodes = []  # We haven't rest any ARTa nodes for this input pattern yet\n",
        "\n",
        "        while not resonant_ab:\n",
        "            J, x = self._resonance_search(input_vector, already_reset_nodes, rho_a)\n",
        "\n",
        "            # Desired output for input number i\n",
        "            z = np.minimum(class_vector, self.weight_ab[J, :])   # Fab activation vector, z\n",
        "            # (Called x_ab in Fuzzy ARTMAP paper)\n",
        "            # Test for Fab resonance\n",
        "\n",
        "            if np.sum(z)/np.sum(class_vector) >= self.rho_ab:     # We have an Fab match\n",
        "                resonant_ab = True\n",
        "            # This will cause us to leave the\n",
        "            # while resonant_ab==0 loop and\n",
        "            # go on to do learning.\n",
        "\n",
        "            else: # We have an Fab mismatch\n",
        "                resonant_ab = False\n",
        "                # This makes us go through\n",
        "                # the resonant_ab==0 loop again\n",
        "                # resonant_a = False\n",
        "                # This makes us go through\n",
        "                # ARTa search again, this\n",
        "                # search being inside the\n",
        "                # resonant_ab==0 loop\n",
        "                # Increase rho_a vigilance.\n",
        "                # This will cause F2a node J to get reset when\n",
        "                # we go back through the ARTa search loop again.\n",
        "                # Also, *for this input*, the above-baseline\n",
        "                # vigilance will cause a finer ARTa category to win\n",
        "\n",
        "                rho_a = np.sum(x)/np.sum(input_vector) + self.epsilon\n",
        "\n",
        "            # End of the while loop searching for ARTa resonance\n",
        "            # If resonant_a = 0, we pick the next highest Tj\n",
        "            # and see if *that* node resonates, i.e. goto \"while\"\n",
        "            # If resonant_a = 1, we have found an ARTa resonance,\n",
        "            # namely node J\n",
        "            # So we go on to see if we get Fab match with node J\n",
        "\n",
        "        #### End of the while resonant_ab==0 loop.\n",
        "        #### Now we have a resonating ARTa output\n",
        "        #### which gives a match at the Fab layer.\n",
        "        #### So, we go on to have learning\n",
        "        #### in the w_a and w_ab weights\n",
        "\n",
        "\n",
        "        #### Let the winning, matching node J learn\n",
        "\n",
        "        self.weight_a[J, :] = self.beta * x + (1-self.beta) * self.weight_a[J, :]\n",
        "        # NB: x = min(A,w_J) = I and w\n",
        "        #### Learning on F1a <--> f2a weights\n",
        "\n",
        "        self.weight_ab[J, :] = self.beta * z + (1-self.beta) * self.weight_ab[J, :]\n",
        "        # NB: z=min(b,w_ab(J))=b and w\n",
        "\n",
        "    def predict(self, input_vector: np.array):\n",
        "        rho_a = 0\n",
        "        # We start off with ARTa vigilance at baseline\n",
        "        resonant_a = False\n",
        "\n",
        "        # We're not resonating in the ARTa module yet\n",
        "        resonant_ab = False\n",
        "\n",
        "        # Not resonating in the Fab match layer either\n",
        "        already_reset_nodes = []  # We haven't rest any ARTa nodes for this input pattern yet\n",
        "\n",
        "        while not resonant_ab:\n",
        "            J, x = self._resonance_search(input_vector, already_reset_nodes, rho_a, False)\n",
        "\n",
        "            # Desired output for input number i\n",
        "            if J == -1:\n",
        "                return np.zeros_like(self.weight_ab)\n",
        "\n",
        "            z = self.weight_ab[J, None]   # Fab activation vector, z\n",
        "            # prediction_transliteration = self.weight_ab[:,J]/sum(self.weight_ab[:,J])\n",
        "            # (Called x_ab in Fuzzy ARTMAP paper)\n",
        "            resonant_ab = True\n",
        "            # prediction_transliteration = self.weight_ab[J,:]/np.sum(self.weight_ab[J,:])\n",
        "            # print(prediction_transliteration)\n",
        "\n",
        "\n",
        "            # End of the while loop searching for ARTa resonance\n",
        "            # If resonant_a = 0, we pick the next highest Tj\n",
        "            # and see if *that* node resonates, i.e. goto \"while\"\n",
        "            # If resonant_a = 1, we have found an ARTa resonance,\n",
        "            # namely node J\n",
        "            # So we go on to see if we get Fab match with node J\n",
        "\n",
        "        #### End of the while resonant_ab==0 loop.\n",
        "        #### Now we have a resonating ARTa output\n",
        "        #### which gives a match at the Fab layer.\n",
        "        #### So, we go on to have learning\n",
        "        #### in the w_a and w_ab weights\n",
        "\n",
        "\n",
        "        #### Let the winning, matching node J learn\n",
        "\n",
        "        # self.weight_a[:, J, np.newaxis] = self.beta * x + (1-self.beta) * self.weight_a[:, J, np.newaxis]\n",
        "        # # NB: x = min(A,w_J) = I and w\n",
        "        # #### Learning on F1a <--> f2a weights\n",
        "\n",
        "        # self.weight_ab[J, :, np.newaxis] = self.beta * z + (1-self.beta) * self.weight_ab[J, :, np.newaxis]\n",
        "        # NB: z=min(b,w_ab(J))=b and w\n",
        "        return z\n",
        "\n",
        "    @staticmethod\n",
        "    def complement_encode(original_vector: np.array) -> np.array:\n",
        "        # Calculate the complement of the original vector\n",
        "        complement = 1 - original_vector\n",
        "\n",
        "        # Stack the original vector and its complement horizontally\n",
        "        complement_encoded_value = np.hstack((original_vector, complement))\n",
        "\n",
        "        # Return the complement-encoded value\n",
        "        return complement_encoded_value"
      ],
      "metadata": {
        "id": "iD-Byj69_hut"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tuning Fuzzy ARTMAP (FAM) Neural Networks\n",
        "\n",
        "In this section, we'll explore the key features of Fuzzy ARTMAP (FAM) neural networks and how to fine-tune them for your classification tasks. FAM networks are versatile and can be adjusted to match your specific dataset and desired performance. Let's break down the tuning capabilities and their impact on FAM functionality:\n",
        "\n",
        "### 1. Vigilance (rho_a_bar)\n",
        "\n",
        "**Description:** Vigilance controls how selective FAM nodes are when accepting input patterns. Higher values make nodes more selective, while lower values make them more lenient.\n",
        "\n",
        "**Impact:**\n",
        "- **Increase:** Higher vigilance leads to finer-grained categories. Nodes accept only highly similar patterns.\n",
        "- **Decrease:** Lower vigilance results in coarser-grained categories. Nodes accept a broader range of patterns.\n",
        "\n",
        "**Standard Starting Value:** Typically set around 0.95.\n",
        "\n",
        "**Tuning Based on Outputs:**\n",
        "- If categories are too fine or many patterns are rejected, decrease vigilance.\n",
        "- If categories are too broad or categories overlap, increase vigilance.\n",
        "\n",
        "### 2. Learning Rate (beta)\n",
        "\n",
        "**Description:** Learning rate (`beta`) determines how much weights adapt during learning. High values mean faster learning but can lead to instability. Low values result in slower but more stable learning.\n",
        "\n",
        "**Impact:**\n",
        "- **Increase:** Faster learning, but may be less stable.\n",
        "- **Decrease:** Slower but more stable learning.\n",
        "\n",
        "**Standard Starting Value:** Often set to 1 for fast learning.\n",
        "\n",
        "**Tuning Based on Outputs:**\n",
        "- If learning is too slow, increase beta.\n",
        "- If the network is unstable or overshoots, decrease beta.\n",
        "\n",
        "### 3. Map Field Vigilance (rho_ab)\n",
        "\n",
        "**Description:** `rho_ab` controls F2 layer nodes' willingness to accept patterns from the ARTa layer.\n",
        "\n",
        "**Impact:**\n",
        "- **Increase:** Nodes in F2 become more selective.\n",
        "- **Decrease:** Nodes in F2 become less selective.\n",
        "\n",
        "**Standard Starting Value:** Typically set around 0.95.\n",
        "\n",
        "**Tuning Based on Outputs:**\n",
        "- If F2 nodes don't activate, decrease `rho_ab`.\n",
        "- If F2 nodes activate too easily, increase `rho_ab`.\n",
        "\n",
        "### 4. Node Growth (max_nodes)\n",
        "\n",
        "**Description:** You can limit the maximum number of nodes in the F2 layer. When this limit is reached, you can choose to allow node growth or reset existing nodes.\n",
        "\n",
        "**Impact:**\n",
        "- **Node Growth:** Allows the network to adapt to new data by adding nodes.\n",
        "- **Reset Nodes:** Resets existing nodes to accommodate new learning.\n",
        "\n",
        "**Standard Starting Value:** Set to a reasonable maximum number of nodes (e.g., 20).\n",
        "\n",
        "**Tuning Based on Outputs:**\n",
        "- If categories become too rigid or new data isn't accommodated, allow node growth.\n",
        "- If the network becomes too complex or unstable, reset nodes.\n",
        "\n",
        "### 5. Other Parameters\n",
        "\n",
        "Depending on the implementation, there may be additional parameters like epsilon, which adjusts vigilance based on mismatch.\n",
        "\n",
        "Now that you understand these tuning capabilities, it's essential to monitor the network's performance and adjust these parameters based on the desired changes:\n",
        "- Experiment with different values for each parameter.\n",
        "- Observe how changes impact the network's ability to categorize patterns.\n",
        "- Fine-tune until you achieve the desired categorization granularity and learning behavior.\n",
        "\n",
        "Remember that the choice of parameter values should be data-dependent. Regularly assess the network's outputs and adapt your settings to optimize its performance for your specific classification task.\n"
      ],
      "metadata": {
        "id": "1qWdnBT8IjzH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Initialize FAM"
      ],
      "metadata": {
        "id": "FB-ypUCdZmZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Fuzzy ARTMAP (FAM) model\n",
        "fam = FuzzyArtMap(f1_size=num_features, number_of_labels=num_categories, committed_beta=learning_rate, rho_a_bar=vigilance)\n",
        "pfam = ProceduralFuzzyArtMap(f1_size=num_features, number_of_categories=num_categories, rho_a_bar=vigilance)"
      ],
      "metadata": {
        "id": "XhoXoPab7OcA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 FAM Train and Test"
      ],
      "metadata": {
        "id": "tf1jKD7dZwjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train FuzzyARTMAP\n",
        "for i in range(len(X_train)):\n",
        "    input_vector = FuzzyArtMap.complement_encode(X_train[i])\n",
        "    target_vector = FuzzyArtMap.complement_encode(y_train[i, None, None])\n",
        "    # Execute FAM Training\n",
        "    fam.train(input_vector, target_vector)\n",
        "    pfam.train(input_vector.numpy(), target_vector.numpy())"
      ],
      "metadata": {
        "id": "iLUCl5Ee7TPj"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test FuzzyARTMAP\n",
        "y_predf = []\n",
        "correct_predictions = 0\n",
        "for i in range(len(X_test)):\n",
        "    #input_vector = X_test[i]\n",
        "    input_vector = FuzzyArtMap.complement_encode(X_test[i])\n",
        "    # switch these to use the streamlined vs. procedural version\n",
        "    category = pfam.predict(input_vector.numpy())\n",
        "    # category, _ = fam.predict(input_vector)\n",
        "    y_predf.append(category[0,0])\n",
        "    if category[0,0] == y_test[i]:\n",
        "        correct_predictions += 1\n",
        "# Now, 'predictions' contains the predicted categories for each input in X_test"
      ],
      "metadata": {
        "id": "yl0fxvCq7VTB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predf)"
      ],
      "metadata": {
        "id": "JZdnIQOHBbBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.5 FAM Calculate and Print Metrics"
      ],
      "metadata": {
        "id": "nT7LaBpcK9uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate FAM Metrics\n",
        "accuracyf = accuracy_score(y_test, y_predf)\n",
        "auc_rocf = roc_auc_score(y_test, y_predf)\n",
        "f1f = f1_score(y_test, y_predf)\n",
        "precisionf = precision_score(y_test, y_predf)\n",
        "sensitivityf = recall_score(y_test, y_predf)\n",
        "tnf, fpf, fnf, tpf = confusion_matrix(y_test, y_predf).ravel()\n",
        "specificityf = tnf / (tnf + fpf)"
      ],
      "metadata": {
        "id": "EbxOMoRfK-YE"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print FAM Metrics\n",
        "print('### FAM Metrics ###')\n",
        "print(f\"Accuracy: {accuracyf}\")\n",
        "print(f\"AUC-ROC: {auc_rocf}\")\n",
        "print(f\"F1 Score: {f1f}\")\n",
        "print(f\"Precision: {precisionf}\")\n",
        "print(f\"Sensitivity (Recall): {sensitivityf}\")\n",
        "print(f\"Specificity: {specificityf}\")\n",
        "print(f\"True Negatives: {tnf}\")\n",
        "print(f\"False Positives: {fpf}\")\n",
        "print(f\"False Negatives: {fnf}\")\n",
        "print(f\"True Positives: {tpf}\")"
      ],
      "metadata": {
        "id": "cjzK1ndcK_U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Model Comparison Table [Optional]"
      ],
      "metadata": {
        "id": "JBLRoy91MXZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Metrics Comparison Table\n",
        "# Define Table width and Title\n",
        "tablewidth = 85\n",
        "comparison_title = \"Model Comparison: KNN vs FAM\"\n",
        "padding = \"#\" * ((tablewidth - len(comparison_title)) // 2)\n",
        "centered_title = f\"{padding} {comparison_title} {padding}\"\n",
        "# Print Table amd Column Titles\n",
        "print(centered_title) # Table Title\n",
        "print(\"-\" * tablewidth)  # Line\n",
        "print(f\"{'Metric':<25} {'KNN':<20} {'FAM':<20} {'Diff'}\")  # Define Column Titles\n",
        "print(\"-\" * tablewidth)  # Line\n",
        "# Print Table Data\n",
        "print(f\"{'Accuracy:':<25} {accuracyk:<20.3f} {accuracyf:<20.3f} {accuracyk - accuracyf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'AUC-ROC:':<25} {auc_rock:<20.3f} {auc_rocf:<20.3f} {auc_rock - auc_rocf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'F1 Score:':<25} {f1k:<20.3f} {f1f:<20.3f} {f1k - f1f:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'Precision:':<25} {precisionk:<20.3f} {precisionf:<20.3f} {precisionk - precisionf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'Sensitivity (Recall):':<25} {sensitivityk:<20.3f} {sensitivityf:<20.3f} {sensitivityk - sensitivityf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'Specificity:':<25} {specificityk:<20.3f} {specificityf:<20.3f} {specificityk - specificityf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'True Negatives:':<25} {tnk:<20.3f} {tnf:<20.3f} {tnk - tnf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'False Positives:':<25} {fpk:<20.3f} {fpf:<20.3f} {fpk - fpf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'False Negatives:':<25} {fnk:<20.3f} {fnf:<20.3f} {fnk - fnf:.3f}\")  # Calculate and display the difference\n",
        "print(f\"{'True Positives:':<25} {tpk:<20.3f} {tpf:<20.3f} {tpk - tpf:.3f}\")  # Calculate and display the difference"
      ],
      "metadata": {
        "id": "T9OOLO9dMZ49"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}